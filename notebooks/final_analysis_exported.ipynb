{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VARIABLES\n",
    "SEARCH_PATH = '../youtube_channels/output/'\n",
    "JSON_FILE = 'trendings-brasileirao3.json'\n",
    "TRENDINS_PATH = '../datasets/trendings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET RESULT SEARCH DATAFRAME FROM JSON FILE\n",
    "def readSearchResult():\n",
    "    try:\n",
    "        df = pd.read_json(SEARCH_PATH + JSON_FILE, encoding='utf-8')\n",
    "        return df\n",
    "    except ValueError as ve:\n",
    "        print(ve)\n",
    "        return None\n",
    "    \n",
    "df_search = readSearchResult()\n",
    "df_search.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVE VALUES FROM ARRAY (BRACKETS)\n",
    "df_search['channel_name'] = df_search['channel_name'].str.get(0)\n",
    "df_search['channel_account'] = df_search['channel_account'].str.get(0)\n",
    "df_search['channel_url'] = df_search['channel_url'].str.get(0)\n",
    "df_search['subscribers'] = df_search['subscribers'].str.get(0)\n",
    "df_search['num_views'] = df_search['num_views'].str.get(0)\n",
    "df_search['num_videos'] = df_search['num_videos'].str.get(0)\n",
    "df_search['last_avg_likes'] = df_search['last_avg_likes'].str.get(0)\n",
    "df_search['last_avg_views'] = df_search['last_avg_views'].str.get(0)\n",
    "df_search['last_avg_comments'] = df_search['last_avg_comments'].str.get(0)\n",
    "df_search.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONVERT DATA TYPES\n",
    "df_search = df_search.convert_dtypes()\n",
    "df_search.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADDING NEW COLUMNS\n",
    "df_search.loc[:, [\"num_trend_videos\",\"mean_trend_likes\",\"mean_trend_views\",\"mean_trend_comments\"]] = 0\n",
    "df_search.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET RESULT SEARCH DATAFRAME FROM JSON FILE\n",
    "def readTrendings():\n",
    "    try:\n",
    "        df = pd.read_json(TRENDINS_PATH, encoding='utf-8')\n",
    "        return df\n",
    "    except ValueError as ve:\n",
    "        print(ve)\n",
    "        return None\n",
    "\n",
    "df_trendings = readTrendings()\n",
    "df_trendings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTIONS TO GET TRENDING DATA\n",
    "## GETTING NUM TRENDING VIDEOS (VALIDATE FROM CHANNEL ACCOUNT)\n",
    "def getNumTrendingVideos(channel_account):\n",
    "    return df_trendings[df_trendings['video_channel_account'] == channel_account]['video_url'].count()\n",
    "\n",
    "## GETTING MEAN TRENDINGS\n",
    "def getMeansTrendingsVideos(channel_account, column):\n",
    "    return round(df_trendings[df_trendings['video_channel_account'] == channel_account][column].mean(), 2)\n",
    "\n",
    "## TESTING \n",
    "print(getNumTrendingVideos('@espnbrasil'))\n",
    "print(getMeansTrendingsVideos('@espnbrasil', 'likes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADDING NEW VALUES IN SEARCH RESULT\n",
    "for index, row in df_search.iterrows():\n",
    "    if not df_trendings[df_trendings['video_channel_account'] == row['channel_account']].empty:\n",
    "        df_search.loc[index,['num_trend_videos']] = getNumTrendingVideos(row['channel_account'])\n",
    "        df_search.loc[index, ['mean_trend_likes']] = getMeansTrendingsVideos(row['channel_account'], 'likes')\n",
    "        df_search.loc[index, ['mean_trend_views']] = getMeansTrendingsVideos(row['channel_account'], 'views')\n",
    "        df_search.loc[index, ['mean_trend_comments']] = getMeansTrendingsVideos(row['channel_account'], 'comments')\n",
    "\n",
    "df_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PEARSON CORRELATION MATRIX\n",
    "pg.rcorr(df_search, method = 'pearson', upper = 'pval', \n",
    "         decimals = 4, \n",
    "         pval_stars = {0.01: '***', 0.05: '**', 0.10: '*'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNING FATORIAL AND PCA CLASSIFICATION (UNSUPERVISED MACHINE LEARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET DATAFRAME INFORMATION\n",
    "df_search.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DESCRIBING DATA\n",
    "df_search.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVING QUALITY VARIABLES\n",
    "df_pca = df_search.drop(columns=['channel_name', 'channel_account', 'channel_url', 'keywords'])\n",
    "\n",
    "## CONVERT VARIABLE TYPES TO NUMPY TYPES (NECESSARY FOR BARTLLET'S TEST)\n",
    "df_pca['last_avg_likes'] = df_pca['last_avg_likes'].astype(np.float64)\n",
    "df_pca['last_avg_views'] = df_pca['last_avg_views'].astype(np.float64)\n",
    "df_pca['last_avg_comments'] = df_pca['last_avg_comments'].astype(np.float64)\n",
    "df_pca['mean_trend_likes'] = df_pca['mean_trend_likes'].astype(np.float64)\n",
    "df_pca['mean_trend_views'] = df_pca['mean_trend_views'].astype(np.float64)\n",
    "df_pca['mean_trend_comments'] = df_pca['mean_trend_comments'].astype(np.float64)\n",
    "df_pca['subscribers'] = df_pca['subscribers'].astype(np.int64)\n",
    "df_pca['num_videos'] = df_pca['num_videos'].astype(np.int64)\n",
    "df_pca['num_views'] = df_pca['num_views'].astype(np.int64)\n",
    "df_pca['num_trend_videos'] = df_pca['num_trend_videos'].astype(np.int64)\n",
    "\n",
    "df_pca.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  GET DF_PCA INFO\n",
    "df_pca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANALYZING PEARSON CORRELATION\n",
    "\n",
    "# CORRELATION MATRIX\n",
    "\n",
    "corr = df_pca.corr()\n",
    "\n",
    "## GRAPHICS\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr.columns,\n",
    "        y = corr.index,\n",
    "        z = np.array(corr),\n",
    "        text=corr.values,\n",
    "        texttemplate='%{text:.3f}',\n",
    "        colorscale='viridis'))\n",
    "\n",
    "fig.update_layout(\n",
    "    height = 750,\n",
    "    width = 750,\n",
    "    yaxis=dict(autorange=\"reversed\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bartlett's Test of Sphericity and Get P value\n",
    "bartlett, p_value = calculate_bartlett_sphericity(df_pca)\n",
    "\n",
    "print(f'Qui² Bartlett: {round(bartlett, 2)}')\n",
    "print(f'p-valor: {round(p_value, 4)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA DEFINING (PRINCIPAL METHOD) --> TEST\n",
    "fa = FactorAnalyzer(n_factors=10, method='principal', rotation=None).fit(df_pca)\n",
    "eigenvalues = fa.get_eigenvalues()[0]\n",
    "\n",
    "np.count_nonzero(eigenvalues > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA DEFINING NUM FACTORS (DERIVATIVE) FUNCTION\n",
    "def getNumFactors(num_factors):\n",
    "    fa = FactorAnalyzer(n_factors=num_factors, method='principal', rotation=None).fit(df_pca)\n",
    "    eigenvalues = fa.get_eigenvalues()[0]\n",
    "\n",
    "    ## APPLYING KAISER CRITERIA (EIGENVALUES > 1) = FOUR FACTORS\n",
    "    return np.count_nonzero(eigenvalues > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APPLYING KAISER CRITERIA (EIGENVALUES > 1) = FOUR FACTORS\n",
    "### PCA DEFINING (PRINCIPAL METHOD)\n",
    "num_factors = getNumFactors(len(df_pca.columns))\n",
    "fa = FactorAnalyzer(n_factors=num_factors, method='principal', rotation=None).fit(df_pca)\n",
    "eigenvalues = fa.get_eigenvalues()[0]\n",
    "\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GETTING FACTOR VARIANCE AND PLOT TABLE\n",
    "\n",
    "eigenvalues_factors = fa.get_factor_variance()\n",
    "\n",
    "tabela_eigen = pd.DataFrame(eigenvalues_factors)\n",
    "tabela_eigen.columns = [f\"fator_{i+1}\" for i, v in enumerate(tabela_eigen.columns)]\n",
    "tabela_eigen.index = ['Autovalor','Variância', 'Variância Acumulada']\n",
    "tabela_eigen = tabela_eigen.T\n",
    "\n",
    "print(tabela_eigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACUMULATE VARIANCE GRAPHICS\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.barplot(x=tabela_eigen.index, y=tabela_eigen['Variância'], data=tabela_eigen, palette='magma')\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars, fontsize=12)\n",
    "plt.title(\"Fatores Extraídos\", fontsize=16)\n",
    "plt.xlabel(f\"{tabela_eigen.shape[0]} fatores que explicam {round(tabela_eigen['Variância'].sum()*100,2)}% da variância\", fontsize=12)\n",
    "plt.ylabel(\"Porcentagem de variância explicada\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD FACTORS\n",
    "l_factors = fa.loadings_\n",
    "\n",
    "load_table = pd.DataFrame(l_factors)\n",
    "load_table.columns = [f\"fator_{i+1}\" for i, v in enumerate(load_table.columns)]\n",
    "load_table.index = df_pca.columns\n",
    "\n",
    "print(load_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING PLOTS\n",
    "plt.figure(figsize=(12,8))\n",
    "load_chart = load_table.reset_index()\n",
    "plt.scatter(load_chart['fator_1'], load_chart['fator_2'], s=50, color='blue')\n",
    "\n",
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(point['x'] + 0.05, point['y'], point['val'])\n",
    "\n",
    "label_point(x = load_chart['fator_1'],\n",
    "            y = load_chart['fator_2'],\n",
    "            val = load_chart['index'],\n",
    "            ax = plt.gca()) \n",
    "\n",
    "plt.axhline(y=0, color='grey', ls='--')\n",
    "plt.axvline(x=0, color='grey', ls='--')\n",
    "plt.ylim([-1.1,1.1])\n",
    "plt.xlim([-1.1,1.1])\n",
    "plt.title(\"Loading Plot\", fontsize=16)\n",
    "plt.xlabel(f\"Fator 1: {round(tabela_eigen.iloc[0]['Variância']*100,2)}% de variância explicada\", fontsize=12)\n",
    "plt.ylabel(f\"Fator 2: {round(tabela_eigen.iloc[1]['Variância']*100,2)}% de variância explicada\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING PLOTS (3D)\n",
    "\n",
    "load_chart = load_table.reset_index()\n",
    "fig = px.scatter_3d(load_chart, x='fator_1', y='fator_2', z='fator_3',\n",
    "                    color='index',\n",
    "                    color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "fig.update_layout(\n",
    "    height = 750,\n",
    "    width = 1200)\n",
    "fig.update_layout(legend_title_text = \"Loading Plot (3D)\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_table_graph = load_table.reset_index()\n",
    "load_table_graph = load_table_graph.melt(id_vars='index')\n",
    "\n",
    "sns.barplot(data=load_table_graph, x='variable', y='value', hue='index', palette='bright')\n",
    "plt.legend(title='Variáveis', bbox_to_anchor=(1,1), fontsize = '6')\n",
    "plt.title('Cargas Fatoriais', fontsize='12')\n",
    "plt.xlabel(xlabel=None)\n",
    "plt.ylabel(ylabel=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMMUNALITIES\n",
    "communalities = fa.get_communalities()\n",
    "\n",
    "commun_tables = pd.DataFrame(communalities)\n",
    "commun_tables.columns = ['Comunalidades']\n",
    "commun_tables.index = df_pca.columns\n",
    "\n",
    "print(commun_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT FACTORS TO DATAFRAME\n",
    "factors = pd.DataFrame(fa.transform(df_pca))\n",
    "factors.columns =  [f\"fator_{i+1}\" for i, v in enumerate(factors.columns)]\n",
    "\n",
    "# ADDING FACTORS INTO DATAFRAME SEARCH\n",
    "df_search = pd.concat([df_search.reset_index(drop=True), factors], axis=1)\n",
    "df_search.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SCORES FACTOR\n",
    "scores = fa.weights_\n",
    "\n",
    "scores_table = pd.DataFrame(scores)\n",
    "scores_table.columns = [f\"fator_{i+1}\" for i, v in enumerate(scores_table.columns)]\n",
    "scores_table.index = df_pca.columns\n",
    "\n",
    "print(scores_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_graph = scores_table.reset_index()\n",
    "scores_graph = scores_graph.melt(id_vars='index')\n",
    "\n",
    "sns.barplot(data=scores_graph, x='variable', y='value', hue='index', palette='viridis')\n",
    "plt.legend(title='Variáveis', bbox_to_anchor=(1,1), fontsize = '6')\n",
    "plt.title('Scores Fatoriais', fontsize='12')\n",
    "plt.xlabel(xlabel=None)\n",
    "plt.ylabel(ylabel=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## weighted sum (sum the factors)\n",
    "df_search['ranking'] = 0\n",
    "\n",
    "for index, item in enumerate(list(tabela_eigen.index)):\n",
    "    variancia = tabela_eigen.loc[item]['Variância']\n",
    "\n",
    "    df_search['ranking'] = df_search['ranking'] + df_search[tabela_eigen.index[index]]*variancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEE CORRELATION FROM VARIABLES (PEARSON)\n",
    "pg.rcorr(df_search[df_search.columns], \n",
    "         method = 'pearson', upper = 'pval', \n",
    "         decimals = 4, \n",
    "         pval_stars = {0.01: '***', 0.05: '**', 0.10: '*'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## final ranking\n",
    "df_search.sort_values(by=['ranking'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING FINAL DATAFRAME IN A TABLE\n",
    "\n",
    "df_final = df_search.drop(columns=['channel_url', \n",
    "                                   'subscribers', \n",
    "                                   'last_avg_likes', \n",
    "                                   'num_views', \n",
    "                                   'num_videos', \n",
    "                                   'keywords', \n",
    "                                   'num_trend_videos',\n",
    "                                   'mean_trend_likes',\n",
    "                                   'mean_trend_views',\n",
    "                                   'mean_trend_comments',\n",
    "                                   'last_avg_views',\n",
    "                                   'last_avg_comments'])\n",
    "\n",
    "## REORDER BY RANKING\n",
    "df_final = df_final.sort_values(by=['ranking'], ascending=False)\n",
    "\n",
    "## RESET INDEX VALUES\n",
    "df_final.reset_index(level=0, inplace=True)\n",
    "df_final.index = np.arange(1, len(df_final)+1)\n",
    "df_final.rename(columns={'index': 'n'}, inplace=True)\n",
    "\n",
    "from tabulate import tabulate\n",
    "tabela = tabulate(df_final, headers='keys', tablefmt='grid', numalign='center')\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.text(0.1, 0.1, tabela, {'family': 'monospace', 'size': 30})\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_usp_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
